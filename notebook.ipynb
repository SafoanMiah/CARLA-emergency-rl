{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emergency Vehicle Autonomous Driving (RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Goal is to train a autonomous emergency vehicle model (ambulance, police, firefighter, etc.).\n",
    "Prioritizing speed, collision avoidance, while not so much road laws; like speed and traffic lights.\n",
    "\n",
    "I'll begin with a more basic model with a few sensors and minimal traffic then incrementally add complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "!CarlaUE4.exe -benchmark -fps=2000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carla Python API\n",
    "Used to communicate with the server â€“ `CarlaUE4.exe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the CARLA server, only run this after starting the server (see README.md)\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00083375  0.00095224  0.59999996]\n"
     ]
    }
   ],
   "source": [
    "map = world.get_map()\n",
    "random_spawn = random.choice(world.get_map().get_spawn_points()).location\n",
    "# Convert world coordinates to GNSS\n",
    "destination = map.transform_to_geolocation(random_spawn)\n",
    "print(np.array([destination.latitude, destination.longitude, destination.altitude]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensors:\n",
      "other.collision | camera.depth | camera.optical_flow | camera.normals | other.lane_invasion | camera.dvs | other.imu | other.gnss | other.obstacle | other.radar | lidar.ray_cast_semantic | lidar.ray_cast | camera.rgb | camera.semantic_segmentation | other.rss | camera.instance_segmentation | "
     ]
    }
   ],
   "source": [
    "actors_list = []\n",
    "\n",
    "# get blueprints and spawn points\n",
    "bp_lib = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "    \n",
    "print('Sensors:')\n",
    "for bp in bp_lib.filter('sensor'):\n",
    "    print(bp.id[7:], end=' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawning ego vehicle (agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_vehicle():\n",
    "    # spawn vehicle, ambulance\n",
    "    vehicle_bp = bp_lib.find('vehicle.ford.ambulance')\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points)) # random locations spawn\n",
    "\n",
    "    return vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle = spawn_vehicle()\n",
    "# actors_list.append(vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensors to the vehicle, callback functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing RGB image\n",
    "* Raw data is a 1D flat array of pixels\n",
    "* Reshape to 4 channel image so instead it's, array[y, x] = RGBA\n",
    "* Drop the alpha, RGBA -> RGB, irrelevant\n",
    "\n",
    "Env parameter is for the enviroment class, for when it is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH = 480\n",
    "IM_HEIGHT = 320\n",
    "IM_FOV = 110\n",
    "\n",
    "def spawn_rgb_camera(to_attach):\n",
    "    # RGB Camera\n",
    "    camera_rgb_bp = bp_lib.find('sensor.camera.rgb')\n",
    "    camera_rgb_bp.set_attribute('image_size_x', f'{IM_WIDTH}')\n",
    "    camera_rgb_bp.set_attribute('image_size_y', f'{IM_HEIGHT}')\n",
    "    camera_rgb_bp.set_attribute('fov', f'{IM_FOV}')\n",
    "    rgb_transform = carla.Transform(carla.Location(x=2.5, z=1.5))  # Front-mounted\n",
    "    camera_rgb = world.spawn_actor(camera_rgb_bp, rgb_transform, attach_to=to_attach)\n",
    "    return camera_rgb\n",
    "\n",
    "# callback function\n",
    "def process_rgb_image(image, env):\n",
    "    '''Process an RGB image'''\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\")) \n",
    "    array = np.reshape(array, (image.height, image.width, 4)) \n",
    "    env.rgb_image = array[:, :, :3]\n",
    "    \n",
    "    # # Display image, uncomment to show\n",
    "    # cv2.imshow(\"RGB Camera\", array)  # Display using OpenCV\n",
    "    # cv2.waitKey(1)  # Wait for a key press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_rgb = spawn_rgb_camera(vehicle)\n",
    "# actors_list.append(camera_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Lidar data\n",
    "* Using point cloud data, not image data; set of 3D points for 3D objects\n",
    "* Reshape to 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_lidar_sensor(to_attach):\n",
    "    # LiDAR Sensor\n",
    "    lidar_bp = bp_lib.find('sensor.lidar.ray_cast')\n",
    "    lidar_bp.set_attribute('range', '50')\n",
    "    lidar_transform = carla.Transform(carla.Location(z=2.5)) # Front-mounted\n",
    "    lidar_sensor = world.spawn_actor(lidar_bp, lidar_transform, attach_to=to_attach)\n",
    "    return lidar_sensor\n",
    "\n",
    "# callback function\n",
    "def process_lidar_pc(point_cloud, env, points=360):\n",
    "    '''Process a LiDAR point cloud to have a fixed number of points'''\n",
    "    array = np.frombuffer(point_cloud.raw_data, dtype=np.dtype('f4'))\n",
    "    positions = array.shape[0] // 3\n",
    "    max_set_3 = int(positions) * 3\n",
    "    point_cloud_array = np.reshape(array[:max_set_3], (positions, 3))\n",
    "    \n",
    "    if positions > points:\n",
    "        # Randomly sample\n",
    "        indices = np.random.choice(positions, points, replace=False)\n",
    "        env.lidar_pc = point_cloud_array[indices]\n",
    "        \n",
    "    elif positions < points:\n",
    "        # Pad with zeros\n",
    "        padding = np.zeros((points - positions, 3), dtype=np.float32)\n",
    "        env.lidar_pc = np.vstack((point_cloud_array, padding))\n",
    "        \n",
    "    else:\n",
    "        env.lidar_pc = point_cloud_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lidar_sensor = spawn_lidar_sensor(vehicle)\n",
    "# actors_list.append(lidar_sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collision sensor\n",
    "* Primarily used to detect when a simulation has failed, i.e. the vehicle has crashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_collision_sensor(to_attach):\n",
    "    # Collision Sensor\n",
    "    collision_bp = bp_lib.find('sensor.other.collision')\n",
    "    collision_sensor = world.spawn_actor(collision_bp, carla.Transform(), attach_to=to_attach)\n",
    "    return collision_sensor\n",
    "   \n",
    "def process_collision(event, env):\n",
    "    '''Process a collision event'''\n",
    "    print(\"COLLISION:\", event)\n",
    "    env.collided = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collision_sensor = spawn_collision_sensor(vehicle)\n",
    "# actors_list.append(collision_sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GNSS sensor\n",
    "* Global position of the vehicle in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_gnss_sensor(to_attach):\n",
    "    # GNSS Sensor\n",
    "    gnss_bp = bp_lib.find('sensor.other.gnss')\n",
    "    gnss_sensor = world.spawn_actor(gnss_bp, carla.Transform(), attach_to=to_attach)\n",
    "    return gnss_sensor\n",
    "\n",
    "def process_gnss_data(data, env):\n",
    "    '''Process GNSS'''\n",
    "    env.current_location = np.array([data.latitude, data.longitude, data.altitude])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destinations\n",
    "Just like in a real world enviorment, an emergency vehicle doesnt just drive around with no aim.\n",
    "It needs a goal (destination) for which to head towards.\n",
    "\n",
    "For this simulation we can make use of a random spawn point from CARLA as the destination. (Implemented in the class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using geopy for distance calculation, as its more accurate than euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(start, desti):\n",
    "    distance = geodesic((start[0], start[1]), (desti[0], desti[1])).meters\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_location_gnss(actor):\n",
    "    location = actor.get_location()\n",
    "    gnss = map.transform_to_geolocation(location)\n",
    "    current = np.array([gnss.latitude, gnss.longitude, gnss.altitude])\n",
    "    \n",
    "    return current\n",
    "\n",
    "def set_destination_gnss(actor):\n",
    "    # Ensure its at least 100m away\n",
    "    \n",
    "    distance = 0\n",
    "    while distance < 100:\n",
    "        random_spawn = random.choice(spawn_points).location\n",
    "        gnss = map.transform_to_geolocation(random_spawn)  # Convert to GNSS\n",
    "        destination = np.array([gnss.latitude, gnss.longitude, gnss.altitude])\n",
    "    \n",
    "        distance = calculate_distance(get_current_location_gnss(actor), destination)\n",
    "        \n",
    "    return destination\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Enviroment Class\n",
    "We'll use open-ai gym for this\n",
    "\n",
    "Observation Space (`Dict`):\n",
    "* RGB Camera Shape: `(IM_WIDTH, IM_HEIGHT, 3)` : `Box` -> Only with visual render\n",
    "* LiDAR Point Cloud Shape: `(N, 3)`; `N` points, `3` x,y,z : `Box`\n",
    "* Collision Shape: `1` : `Discrete`\n",
    "* Current Location Shape: `3` x,y,z : `Box`\n",
    "* Destination Location Shape: `3` x,y,z : `Box`\n",
    "* GNSS Location Shape: `3` lat,long,alt : `Box`\n",
    "\n",
    "Action Space (`Box`):\n",
    "* Steering: `[-1, 1]`, Left : Right\n",
    "* Throttle: `[0,1]`, None : Full acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaEnv(Env):\n",
    "    \n",
    "    def __init__(self, visual_render=False):\n",
    "        '''\n",
    "        Initialize the Env, and sets up the observation and action spaces detailed above\n",
    "        '''\n",
    "        \n",
    "        self.visual_render = visual_render\n",
    "        \n",
    "        # Action space\n",
    "        self.action_space = Box( # ([steering, throttle])\n",
    "            low=np.array([-1.0, 0.1]), # minimum throttle is 0.1, to always be in motion, encourage exploration\n",
    "            high=np.array([1.0, 1.0]),\n",
    "            dtype=np.float32)\n",
    "        \n",
    "        # Observations space\n",
    "        observation_spaces = {}\n",
    "        \n",
    "        if self.visual_render:\n",
    "            rgb_cam_space = Box(\n",
    "                low=0,\n",
    "                high=255,\n",
    "                shape=(IM_HEIGHT, IM_WIDTH, 3),\n",
    "                dtype=np.uint8) # uint8 is for images\n",
    "            observation_spaces['rgb'] = rgb_cam_space\n",
    "        \n",
    "        lidar_space = Box(\n",
    "            low=-100,\n",
    "            high=100,\n",
    "            shape=(360, 3),\n",
    "            dtype=np.float32)\n",
    "        observation_spaces['lidar'] = lidar_space\n",
    "        \n",
    "        collision_space = Discrete(2) # 0 or 1\n",
    "        observation_spaces['collision'] = collision_space\n",
    "        \n",
    "        current_location_space = Box(\n",
    "            low=np.array([-180, -180, -500]),  # Latitude, Longitude, Altitude\n",
    "            high=np.array([180, 180, 500]),\n",
    "            shape=(3,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        observation_spaces['current_location'] = current_location_space\n",
    "        \n",
    "        destination_space = Box(\n",
    "            low=np.array([-180, -180, -500]),\n",
    "            high=np.array([180, 180, 500]),\n",
    "            shape=(3,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        observation_spaces['destination'] = destination_space\n",
    "        \n",
    "        self.observation_space = Dict(observation_spaces)\n",
    "        \n",
    "        # Initialize variables, to the external functions taking in (env)\n",
    "        self.collided = 0 # False\n",
    "        self.rgb_image = np.zeros((IM_HEIGHT, IM_WIDTH, 3), dtype=np.uint8) if self.visual_render else None # Black image\n",
    "        self.lidar_pc = np.zeros((360, 3), dtype=np.float32) # Empty point cloud\n",
    "        \n",
    "        self.actors_list = []\n",
    "    \n",
    "    def reset(self):\n",
    "        '''\n",
    "        Reset Env, respawn agent, and return initial state\n",
    "        '''\n",
    "        \n",
    "        # Reset flags\n",
    "        self.collided = 0\n",
    "        \n",
    "        # Destroy all previous actors\n",
    "        if self.actors_list:\n",
    "            for actor in self.actors_list:\n",
    "                actor.destroy()\n",
    "            self.actors_list.clear()\n",
    "        \n",
    "        # Spawn actor and sensors using previous functions\n",
    "        self.vehicle = spawn_vehicle()\n",
    "        self.lidar_sensor = spawn_lidar_sensor(self.vehicle)\n",
    "        self.collision_sensor = spawn_collision_sensor(self.vehicle)\n",
    "        self.gnss_sensor = spawn_gnss_sensor(self.vehicle)\n",
    "        \n",
    "        # Add actors to list\n",
    "        self.actors_list.extend([self.vehicle, self.lidar_sensor, self.collision_sensor, self.gnss_sensor])\n",
    "        \n",
    "        # Apply callbacks\n",
    "        self.lidar_sensor.listen(lambda data: process_lidar_pc(data, self))\n",
    "        self.collision_sensor.listen(lambda event: process_collision(event, self))\n",
    "        self.gnss_sensor.listen(lambda data: process_gnss_data(data, self))\n",
    "        \n",
    "        # GNSS current and destination        \n",
    "        self.current_location = get_current_location_gnss(self.vehicle)\n",
    "        self.destination = set_destination_gnss(self.vehicle)\n",
    "        \n",
    "        # Return state\n",
    "        obs = {\n",
    "            'lidar': self.lidar_pc,\n",
    "            'collision': self.collided,\n",
    "            'current_location': self.current_location,\n",
    "            'destination': self.destination\n",
    "        }\n",
    "        \n",
    "        # Add RGB image if visual render\n",
    "        if self.visual_render:\n",
    "            self.camera_rgb = spawn_rgb_camera(self.vehicle)\n",
    "            self.actors_list.append(self.camera_rgb)\n",
    "            self.camera_rgb.listen(lambda data: process_rgb_image(data, self))\n",
    "            obs['rgb'] = self.rgb_image\n",
    "        \n",
    "        # Log dictionary\n",
    "        log_dict = {\n",
    "            'visual_render': self.visual_render,\n",
    "            'current_location': self.current_location,\n",
    "            'destination': self.destination,\n",
    "            'distance': calculate_distance(self.current_location, self.destination)\n",
    "        }\n",
    "        print(log_dict)\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def get_reward(self):\n",
    "        '''\n",
    "        Calculate and return reward; to be used in step function\n",
    "        ''' \n",
    "        \n",
    "        reward = 0\n",
    "        \n",
    "        # Reward for collision\n",
    "        if self.collided:\n",
    "            reward -= 200\n",
    "        \n",
    "        # Time penalty\n",
    "        reward -= 0.2\n",
    "        \n",
    "        # Faster = better up to 45 m/s\n",
    "        velocity = self.vehicle.get_velocity()\n",
    "        speed = np.sqrt(velocity.x**2 + velocity.y**2 + velocity.z**2)  # m/s\n",
    "        reward += min(speed, 45) / 3 # no extra rewards after 45 m/s (~ 100mph)\n",
    "        \n",
    "        # In lane and following traffic rules don't matter as it's an emergency vehicle\n",
    "        \n",
    "        # Destination reward\n",
    "        distance = calculate_distance(self.current_location, self.destination)\n",
    "        reward += 100 / (distance + 1)\n",
    "        \n",
    "        # Problems when models destination is in front of it by chance\n",
    "        # if distance < 5.0: # ends in m range\n",
    "        #     reward += 50 \n",
    "        #     done = 1\n",
    "        \n",
    "        return reward\n",
    "        \n",
    "    def step(self, action):\n",
    "        '''\n",
    "        Take action, return next state, reward, done\n",
    "        '''\n",
    "        \n",
    "        # Apply action\n",
    "        steering = float(action[0])\n",
    "        throttle = float(action[1]) * 0 + 1\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=steering))\n",
    "        \n",
    "        # Get reward\n",
    "        reward = self.get_reward()\n",
    "        \n",
    "        # Update current location\n",
    "        self.current_location = get_current_location_gnss(self.vehicle)\n",
    "        \n",
    "        obs = {\n",
    "            'lidar': self.lidar_pc,\n",
    "            'collision': self.collided,\n",
    "            'current_location': self.current_location,\n",
    "            'destination': self.destination\n",
    "        }\n",
    "        \n",
    "        if self.visual_render:\n",
    "            obs['rgb'] = self.rgb_image\n",
    "        \n",
    "        # Done conditions\n",
    "        done = self.collided\n",
    "        \n",
    "        distance = calculate_distance(self.current_location, self.destination)\n",
    "        \n",
    "\n",
    "            \n",
    "        speed = np.sqrt((self.vehicle.get_velocity().x**2) + (self.vehicle.get_velocity().y**2) + (self.vehicle.get_velocity().z**2))\n",
    "        \n",
    "        # Information, speed, current steering, throttle, distance to destination\n",
    "        # Data, min, max\n",
    "        info = {\n",
    "            'reward': reward,\n",
    "            'speed': speed,\n",
    "            'steering': steering,\n",
    "            'throttle': throttle,\n",
    "            'distance': distance\n",
    "        }\n",
    "        \n",
    "        #print(info)\n",
    "        \n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        '''\n",
    "        Display a rendering of the environment, from the spectators POV\n",
    "        This will only work when the server runs in rendering mode\n",
    "        '''\n",
    "        try:\n",
    "            spectator = self.vehicle.get_world().get_spectator()\n",
    "            transform = self.vehicle.get_transform()\n",
    "            \n",
    "            # Make spectator follow vehicle\n",
    "            spectator.set_transform(carla.Transform(\n",
    "                transform.location + carla.Location(z=30.0), # Offset so you get a better view of surroundings also\n",
    "                carla.Rotation(pitch=-60, yaw=transform.rotation.yaw)  # Look at same direction as vehicle\n",
    "            ))\n",
    "        except:\n",
    "            print('Rendering mode likely not enabled, or server not running.')\n",
    "    \n",
    "    def close(self):\n",
    "        '''\n",
    "        Clean up\n",
    "        '''\n",
    "        if self.actors_list:\n",
    "            for actor in self.actors_list:\n",
    "                actor.destroy()\n",
    "            self.actors_list.clear()\n",
    "            \n",
    "        print('Environment cleaned up.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning the Agent\n",
    "Proximal Policy Optimization (PPO) to train the agent (vehicle); well suited for continuous action spaces like steering, throttle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic with python script in PythonAPI/examaples\n",
    "To begin with the trianing wont incorperate traffic, simplified env, once the model learns basic navigation traffic and other real world elements will be incorperated.\n",
    "\n",
    "```cmd\n",
    "!cd ../examples/ && py -3.8 generate_traffic.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular render -> True, Slowest, with spectator\n",
    "# Off-Screen -> True, Faster, no spectator\n",
    "# No-Renders -> False, Fastest, no spectator\n",
    "rendering = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing env for a quick demo, this uses `.sample()` so all the movement are random and not based on any predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize environment\n",
    "# env = CarlaEnv(visual_render=rendering)\n",
    "# env.reset()\n",
    "\n",
    "# for ep in range(1,3): \n",
    "#     obs = env.reset()\n",
    "#     done = 0\n",
    "#     total_reward = 0\n",
    "    \n",
    "#     while done == 0:\n",
    "#         action = env.action_space.sample()\n",
    "#         obs, reward, done, info = env.step(action)\n",
    "#         total_reward += reward\n",
    "        \n",
    "#         env.render()\n",
    "        \n",
    "#         print(info)\n",
    "        \n",
    "#     print('Episode Reward:', total_reward)\n",
    "    \n",
    "# env.close() # Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The policy used is `MultiInputPolicy` due to the obseration space being a `Dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#load model in if exists\n",
    "log_path = os.path.join(\"training\", \"logs\")\n",
    "model_path = os.path.join(\"training\", \"models\")\n",
    "\n",
    "try:\n",
    "    model_ppo = PPO.load('training/models/best_model.zip', device='cuda')\n",
    "    print(\"Model loaded successfully\")\n",
    "except:\n",
    "    print(\"Model not found, training new model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DummyVecEnv` wrapper to vectorize, for `PPO` model training.\n",
    "\n",
    "*unsolved note: cannot make use of `SubprocVecEnv` due to following error:*\n",
    "```console\n",
    "RuntimeError: Pickling of \"carla.libcarla.BlueprintLibrary\" instances is not enabled (http://www.boost.org/libs/python/doc/v2/pickle.html)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\safho\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\safho\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create environment\n",
    "env = DummyVecEnv([lambda: CarlaEnv(visual_render=rendering)])\n",
    "\n",
    "eval_callback = EvalCallback(env,\n",
    "                             eval_freq=10_000,\n",
    "                             best_model_save_path=model_path,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Train model\n",
    "    model_ppo = PPO('MultiInputPolicy', env, verbose=1, tensorboard_log=log_path, device='cuda')\n",
    "    model_ppo.learn(total_timesteps=100_000_000, callback=eval_callback)\n",
    "except:\n",
    "    print(\"Training interrupted. Closing environment.\")\n",
    "finally:\n",
    "    env.close()\n",
    "    model_ppo.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO minimize GPU usage by unecessary rendering, I've enabled no render mode, however also made use of the no render script to get a top down 2d, pygame view of the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further training\n",
    "Increses complexity of the simulation, more realistic\n",
    "\n",
    "* Traffic:\n",
    "    ```console\n",
    "    !py -3.8 PythonAPI/examples/generate_traffic.py\n",
    "    ```\n",
    "* Weather\n",
    "    ```console\n",
    "    !py -3.8 PythonAPI/examples/dynamic_weather.py\n",
    "    ```\n",
    "\n",
    "## Results & Evaluation - In Progress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
